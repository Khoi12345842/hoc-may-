import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, f_regression
from scipy import stats

# Thiáº¿t láº­p trang
st.set_page_config(page_title="Dá»± Ä‘oÃ¡n káº¿t quáº£ há»c táº­p", layout="wide")

# Táº¡o tá»« Ä‘iá»ƒn Ã¡nh xáº¡ tÃªn biáº¿n vÃ  tÃªn hiá»ƒn thá»‹ tiáº¿ng Viá»‡t
feature_names = {
    'gio_hoc_moi_tuan': 'Giá» há»c má»—i tuáº§n',
    'diem_dau_vao': 'Äiá»ƒm Ä‘áº§u vÃ o',
    'diem_trung_binh_truoc': 'Äiá»ƒm trung bÃ¬nh cÃ¡c ká»³ trÆ°á»›c',
    'tham_gia_ngoai_khoa': 'Tham gia ngoáº¡i khÃ³a',
    'gio_giai_tri': 'Giá» giáº£i trÃ­ má»—i tuáº§n',
    'lam_them': 'LÃ m thÃªm',
    'khoang_cach_den_truong': 'Khoáº£ng cÃ¡ch Ä‘áº¿n trÆ°á»ng (km)',
    'gpa': 'Äiá»ƒm GPA',
    # ThÃªm tÃªn cho cÃ¡c Ä‘áº·c trÆ°ng má»›i
    'hoc_per_giai_tri': 'Tá»· lá»‡ há»c táº­p/giáº£i trÃ­',
    'hoc_hieu_qua': 'Thá»i gian há»c hiá»‡u quáº£',
    'diem_nen': 'Äiá»ƒm ná»n há»c thuáº­t',
    'ap_luc': 'Ãp lá»±c há»c táº­p',
    'can_bang': 'CÃ¢n báº±ng há»c táº­p'
}

# TÃªn cÃ¡c mÃ´ hÃ¬nh báº±ng tiáº¿ng Viá»‡t
model_names = {
    "Linear Regression": "Há»“i quy tuyáº¿n tÃ­nh",
    "Ridge Regression": "Há»“i quy Ridge",
    "Lasso Regression": "Há»“i quy Lasso",
    "ElasticNet": "Há»“i quy ElasticNet",
    "Linear Ensemble": "Ensemble cÃ¡c mÃ´ hÃ¬nh tuyáº¿n tÃ­nh"
}
# TiÃªu Ä‘á» á»©ng dá»¥ng
st.title("Dá»± Ä‘oÃ¡n káº¿t quáº£ há»c táº­p cá»§a sinh viÃªn (PhiÃªn báº£n cáº£i tiáº¿n)")
st.write("á»¨ng dá»¥ng nÃ y dá»± Ä‘oÃ¡n Ä‘iá»ƒm GPA cá»§a sinh viÃªn dá»±a trÃªn cÃ¡c yáº¿u tá»‘ Ä‘áº§u vÃ o")

# Sidebar cho viá»‡c táº£i lÃªn dá»¯ liá»‡u vÃ  lá»±a chá»n mÃ´ hÃ¬nh
with st.sidebar:
    st.header("TÃ¹y chá»n")
    uploaded_file = st.file_uploader("Táº£i lÃªn file CSV", type=["csv"])
    
    st.subheader("Lá»±a chá»n mÃ´ hÃ¬nh")
    model_type = st.selectbox(
        "Chá»n loáº¡i mÃ´ hÃ¬nh",
        ["Linear Regression", "Ridge Regression", "Lasso Regression", "ElasticNet", "Linear Ensemble"],
        format_func=lambda x: model_names[x]
    )
    
    # TÃ¹y chá»n Ä‘áº·c biá»‡t cho tá»«ng loáº¡i mÃ´ hÃ¬nh
    if model_type == "Ridge Regression":
        alpha = st.slider("Alpha (regularization strength)", 0.01, 10.0, 1.0, 0.01)
    elif model_type == "Lasso Regression":
        alpha = st.slider("Alpha (regularization strength)", 0.001, 1.0, 0.1, 0.001)
    elif model_type == "ElasticNet":
        alpha = st.slider("Alpha (regularization strength)", 0.001, 1.0, 0.1, 0.001)
        l1_ratio = st.slider("L1 ratio", 0.0, 1.0, 0.5, 0.01)
    
    st.subheader("Xá»­ lÃ½ dá»¯ liá»‡u")
    test_size = st.slider("Tá»· lá»‡ dá»¯ liá»‡u kiá»ƒm tra", 0.1, 0.5, 0.2)
    remove_outliers_option = st.checkbox("Loáº¡i bá» outliers", value=True)
    outlier_threshold = st.slider("NgÆ°á»¡ng outlier (Z-score)", 2.0, 4.0, 3.0, 0.1) if remove_outliers_option else 3.0
    
    st.subheader("Feature Engineering")
    feature_selection = st.checkbox("Sá»­ dá»¥ng lá»±a chá»n tÃ­nh nÄƒng", value=False)
    k_features = st.slider("Sá»‘ lÆ°á»£ng tÃ­nh nÄƒng quan trá»ng nháº¥t", 1, 15, 7) if feature_selection else None
    
    poly_degree = st.slider("Báº­c Ä‘a thá»©c (Polynomial Features)", 1, 3, 1)
    use_interactions = st.checkbox("Sá»­ dá»¥ng tÃ­nh nÄƒng tÆ°Æ¡ng tÃ¡c", value=True)
    use_log_transform = st.checkbox("Sá»­ dá»¥ng biáº¿n Ä‘á»•i Log cho GPA", value=False)
    
    st.subheader("ÄÃ¡nh giÃ¡ vÃ  tÃ¬m tham sá»‘")
    use_grid_search = st.checkbox("TÃ¬m tham sá»‘ tá»‘i Æ°u tá»± Ä‘á»™ng", value=False)
    use_cv = st.checkbox("Sá»­ dá»¥ng cross-validation", value=True)
    # HÃ m loáº¡i bá» outliers
def remove_outliers(df, columns, threshold=3):
    """Loáº¡i bá» outliers sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Z-score"""
    df_clean = df.copy()
    outlier_mask = np.zeros(len(df), dtype=bool)
    
    for col in columns:
        if col in df.columns and df[col].dtype in ['int64', 'float64']:
            z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())
            col_outliers = z_scores > threshold
            outlier_mask = outlier_mask | col_outliers
    
    # Giá»¯ láº¡i cÃ¡c dÃ²ng khÃ´ng pháº£i outlier
    df_clean = df_clean[~outlier_mask]
    n_removed = sum(outlier_mask)
    
    return df_clean, n_removed

# HÃ m táº¡o cÃ¡c Ä‘áº·c trÆ°ng tÆ°Æ¡ng tÃ¡c
def add_interaction_features(X):
    X_new = X.copy()
    
    # Tá»· lá»‡ há»c táº­p/giáº£i trÃ­
    X_new['hoc_per_giai_tri'] = X['gio_hoc_moi_tuan'] / (X['gio_giai_tri'] + 1)
    
    # Thá»i gian há»c hiá»‡u quáº£ (há»c - áº£nh hÆ°á»Ÿng cá»§a viá»‡c lÃ m thÃªm)
    X_new['hoc_hieu_qua'] = X['gio_hoc_moi_tuan'] * (1 - 0.3 * X['lam_them'])
    
    # Äiá»ƒm ná»n há»c thuáº­t
    X_new['diem_nen'] = (X['diem_dau_vao'] + X['diem_trung_binh_truoc']) / 2
    
    # Äiá»ƒm Ã¡p lá»±c (khoáº£ng cÃ¡ch x lÃ m thÃªm)
    X_new['ap_luc'] = X['khoang_cach_den_truong'] * X['lam_them']
    
    # Äiá»ƒm cÃ¢n báº±ng há»c táº­p
    X_new['can_bang'] = X['tham_gia_ngoai_khoa'] * (X['gio_hoc_moi_tuan'] / (X['gio_giai_tri'] + 1))
    
    return X_new

# Táº¡o dá»¯ liá»‡u máº«u náº¿u ngÆ°á»i dÃ¹ng chÆ°a táº£i lÃªn
@st.cache_data
def create_sample_data(n_samples=200):
    np.random.seed(42)
    gio_hoc_moi_tuan = np.random.randint(5, 50, n_samples)
    diem_dau_vao = np.random.uniform(5.0, 10.0, n_samples)
    diem_trung_binh_truoc = np.random.uniform(5.0, 10.0, n_samples)
    tham_gia_ngoai_khoa = np.random.randint(0, 2, n_samples)  # 0: KhÃ´ng, 1: CÃ³
    gio_giai_tri = np.random.randint(5, 40, n_samples)
    lam_them = np.random.randint(0, 2, n_samples)  # 0: KhÃ´ng, 1: CÃ³
    khoang_cach_den_truong = np.random.randint(1, 50, n_samples)  # km
    
    gpa = (0.03 * gio_hoc_moi_tuan + 
           0.3 * diem_dau_vao + 
           0.4 * diem_trung_binh_truoc + 
           0.1 * tham_gia_ngoai_khoa - 
           0.01 * gio_giai_tri - 
           0.1 * lam_them - 
           0.005 * khoang_cach_den_truong +
           np.random.normal(0, 0.3, n_samples))
    
    gpa = np.clip(gpa, 0, 10)
    
    return pd.DataFrame({
        'gio_hoc_moi_tuan': gio_hoc_moi_tuan,
        'diem_dau_vao': diem_dau_vao,
        'diem_trung_binh_truoc': diem_trung_binh_truoc,
        'tham_gia_ngoai_khoa': tham_gia_ngoai_khoa,
        'gio_giai_tri': gio_giai_tri,
        'lam_them': lam_them,
        'khoang_cach_den_truong': khoang_cach_den_truong,
        'gpa': gpa
    })
    # Äá»c dá»¯ liá»‡u
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("ÄÃ£ táº£i lÃªn dá»¯ liá»‡u thÃ nh cÃ´ng!")
else:
    df = create_sample_data()
    st.info("Sá»­ dá»¥ng dá»¯ liá»‡u máº«u. Táº£i lÃªn CSV cá»§a báº¡n Ä‘á»ƒ sá»­ dá»¥ng dá»¯ liá»‡u riÃªng.")

# Xá»­ lÃ½ outliers náº¿u Ä‘Æ°á»£c chá»n
if remove_outliers_option:
    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    df_clean, n_removed = remove_outliers(df, numeric_columns, outlier_threshold)
    st.info(f"ÄÃ£ loáº¡i bá» {n_removed} dÃ²ng dá»¯ liá»‡u ngoáº¡i lai tá»« {len(df)} dÃ²ng.")
    df = df_clean  # Sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch

# Táº¡o báº£n sao cá»§a dá»¯ liá»‡u vá»›i tÃªn cá»™t tiáº¿ng Viá»‡t Ä‘á»ƒ hiá»ƒn thá»‹
df_display = df.copy()
df_display.columns = [feature_names.get(col, col) for col in df.columns]

# Hiá»ƒn thá»‹ dá»¯ liá»‡u
st.header("Dá»¯ liá»‡u")
st.write(df_display.head())

# Thá»‘ng kÃª mÃ´ táº£
st.header("Thá»‘ng kÃª mÃ´ táº£")
st.write(df_display.describe())
# PhÃ¢n tÃ­ch dá»¯ liá»‡u
st.header("PhÃ¢n tÃ­ch dá»¯ liá»‡u")
tab1, tab2, tab3 = st.tabs(["Ma tráº­n tÆ°Æ¡ng quan", "Biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n", "PhÃ¢n phá»‘i dá»¯ liá»‡u"])

with tab1:
    # Ma tráº­n tÆ°Æ¡ng quan vá»›i tÃªn tiáº¿ng Viá»‡t
    corr = df.corr()
    corr_display = pd.DataFrame(
        corr.values,
        columns=[feature_names.get(col, col) for col in corr.columns],
        index=[feature_names.get(col, col) for col in corr.index]
    )
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(corr_display, annot=True, cmap='coolwarm', ax=ax)
    plt.title('Ma tráº­n tÆ°Æ¡ng quan giá»¯a cÃ¡c biáº¿n')
    st.pyplot(fig)

with tab2:
    # Biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n vá»›i tÃªn tiáº¿ng Viá»‡t
    original_cols = list(df.columns[:-1])
    display_cols = [feature_names.get(col, col) for col in original_cols]
    
    # Táº¡o Ã¡nh xáº¡ tá»« tÃªn hiá»ƒn thá»‹ vá» tÃªn gá»‘c
    reverse_mapping = {feature_names.get(col, col): col for col in df.columns}
    
    # Chá»n Ä‘áº·c trÆ°ng X
    feature_display = st.selectbox("Chá»n Ä‘áº·c trÆ°ng X:", display_cols)
    feature_x = reverse_mapping[feature_display]  # Chuyá»ƒn vá» tÃªn gá»‘c
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.scatterplot(x=feature_x, y='gpa', data=df, ax=ax)
    plt.title(f'Má»‘i quan há»‡ giá»¯a {feature_display} vÃ  Äiá»ƒm GPA')
    plt.xlabel(feature_display)
    plt.ylabel(feature_names['gpa'])
    st.pyplot(fig)

with tab3:
    # PhÃ¢n phá»‘i dá»¯ liá»‡u
    feature_to_plot = st.selectbox("Chá»n biáº¿n Ä‘á»ƒ xem phÃ¢n phá»‘i:", 
                                  df.columns, 
                                  format_func=lambda x: feature_names.get(x, x))
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.histplot(df[feature_to_plot], kde=True, ax=ax)
    plt.title(f'PhÃ¢n phá»‘i cá»§a {feature_names.get(feature_to_plot, feature_to_plot)}')
    plt.xlabel(feature_names.get(feature_to_plot, feature_to_plot))
    st.pyplot(fig)
    # XÃ¢y dá»±ng mÃ´ hÃ¬nh
st.header("XÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh")

# TÃ¡ch dá»¯ liá»‡u
X = df.drop('gpa', axis=1)
y = df['gpa']

# Ãp dá»¥ng biáº¿n Ä‘á»•i log cho biáº¿n má»¥c tiÃªu náº¿u Ä‘Æ°á»£c chá»n
if use_log_transform:
    # Äáº£m báº£o GPA > 0 trÆ°á»›c khi Ã¡p dá»¥ng log
    min_gpa = y.min()
    if min_gpa <= 0:
        y = y + abs(min_gpa) + 0.01  # TrÃ¡nh log(0)
    
    y_log = np.log(y)
    y = y_log
    st.info("ÄÃ£ Ã¡p dá»¥ng biáº¿n Ä‘á»•i logarithm cho Ä‘iá»ƒm GPA.")

# ThÃªm Ä‘áº·c trÆ°ng tÆ°Æ¡ng tÃ¡c náº¿u Ä‘Æ°á»£c chá»n
if use_interactions:
    X = add_interaction_features(X)
    # Cáº­p nháº­t thÃ´ng tin
    new_features = [col for col in X.columns if col not in df.columns and col != 'gpa']
    st.info(f"ÄÃ£ thÃªm {len(new_features)} Ä‘áº·c trÆ°ng tÆ°Æ¡ng tÃ¡c má»›i. Tá»•ng sá»‘ Ä‘áº·c trÆ°ng: {X.shape[1]}")

# TÃ¡ch dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

# Táº¡o pipeline
steps = []

# ThÃªm Polynomial Features náº¿u Ä‘Æ°á»£c yÃªu cáº§u
if poly_degree > 1:
    steps.append(('poly', PolynomialFeatures(degree=poly_degree, include_bias=False)))
    st.info(f"Sá»­ dá»¥ng biáº¿n Ä‘á»•i Ä‘a thá»©c báº­c {poly_degree} Ä‘á»ƒ táº¡o thÃªm Ä‘áº·c trÆ°ng.")

# ThÃªm feature selection náº¿u Ä‘Æ°á»£c yÃªu cáº§u
if feature_selection:
    steps.append(('feature_selection', SelectKBest(f_regression, k=k_features)))

# ThÃªm scaling
steps.append(('scaler', StandardScaler()))

# Chá»n mÃ´ hÃ¬nh dá»±a trÃªn lá»±a chá»n
if model_type == "Linear Regression":
    steps.append(('model', LinearRegression()))
elif model_type == "Ridge Regression":
    steps.append(('model', Ridge(alpha=alpha)))
elif model_type == "Lasso Regression":
    steps.append(('model', Lasso(alpha=alpha)))
elif model_type == "ElasticNet":
    steps.append(('model', ElasticNet(alpha=alpha, l1_ratio=l1_ratio)))
elif model_type == "Linear Ensemble":
    # Ensemble cá»§a cÃ¡c mÃ´ hÃ¬nh tuyáº¿n tÃ­nh
    lr = LinearRegression()
    ridge = Ridge(alpha=1.0)
    lasso = Lasso(alpha=0.1)
    elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)
    
    ensemble_model = VotingRegressor([
        ('lr', lr),
        ('ridge', ridge),
        ('lasso', lasso),
        ('elastic', elastic)
    ])
    
    steps.append(('model', ensemble_model))
    st.info("Sá»­ dá»¥ng ensemble cá»§a 4 mÃ´ hÃ¬nh tuyáº¿n tÃ­nh (Linear, Ridge, Lasso, ElasticNet)")

# Táº¡o pipeline
pipeline = Pipeline(steps)
# Sá»­ dá»¥ng GridSearchCV Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u náº¿u Ä‘Æ°á»£c chá»n
if use_grid_search:
    if model_type == "Ridge Regression":
        param_grid = {'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}
    elif model_type == "Lasso Regression":
        param_grid = {'model__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]}
    elif model_type == "ElasticNet":
        param_grid = {
            'model__alpha': [0.001, 0.01, 0.1, 1.0],
            'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]
        }
    else:
        param_grid = {}
    
    if param_grid:
        with st.spinner("Äang tÃ¬m tham sá»‘ tá»‘i Æ°u..."):
            grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')
            grid_search.fit(X_train, y_train)
            pipeline = grid_search.best_estimator_
            st.success(f"ÄÃ£ tÃ¬m tháº¥y tham sá»‘ tá»‘i Æ°u: {grid_search.best_params_}")
    else:
        pipeline.fit(X_train, y_train)
else:
    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    pipeline.fit(X_train, y_train)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
y_pred = pipeline.predict(X_test)

# Chuyá»ƒn Ä‘á»•i ngÆ°á»£c vá» giÃ¡ trá»‹ thá»±c náº¿u Ä‘Ã£ sá»­ dá»¥ng log transform
if use_log_transform:
    y_pred_original = np.exp(y_pred)
    y_test_original = np.exp(y_test)
    r2 = r2_score(y_test_original, y_pred_original)
    mse = mean_squared_error(y_test_original, y_pred_original)
    mae = mean_absolute_error(y_test_original, y_pred_original)
else:
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    # Hiá»ƒn thá»‹ káº¿t quáº£ Ä‘Ã¡nh giÃ¡
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Há»‡ sá»‘ xÃ¡c Ä‘á»‹nh (RÂ²)", f"{r2:.4f}")
with col2:
    st.metric("Sai sá»‘ bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh (MSE)", f"{mse:.4f}")
with col3:
    st.metric("Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh (MAE)", f"{mae:.4f}")

# Hiá»ƒn thá»‹ káº¿t quáº£ cross-validation náº¿u Ä‘Æ°á»£c chá»n
if use_cv:
    st.subheader("ÄÃ¡nh giÃ¡ báº±ng Cross-validation")
    with st.spinner("Äang thá»±c hiá»‡n 5-fold cross-validation..."):
        cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')
        
    st.write(f"RÂ² qua 5-fold cross-validation: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    
    # Náº¿u cv_scores.mean() tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i r2 tá»« test set, mÃ´ hÃ¬nh á»•n Ä‘á»‹nh
    if abs(cv_scores.mean() - r2) < 0.1:
        st.success("MÃ´ hÃ¬nh cÃ³ Ä‘á»™ á»•n Ä‘á»‹nh tá»‘t!")
    else:
        st.warning("MÃ´ hÃ¬nh cÃ³ thá»ƒ khÃ´ng á»•n Ä‘á»‹nh giá»¯a cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau.")

# Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
st.subheader("Káº¿t quáº£ dá»± Ä‘oÃ¡n")
fig, ax = plt.subplots(figsize=(10, 6))

# Sá»­ dá»¥ng dá»¯ liá»‡u gá»‘c náº¿u Ä‘Ã£ Ã¡p dá»¥ng log transform
if use_log_transform:
    plt.scatter(y_test_original, y_pred_original, alpha=0.5)
    plt.plot([y_test_original.min(), y_test_original.max()], 
             [y_test_original.min(), y_test_original.max()], 'r--')
    plt.xlabel('Äiá»ƒm GPA thá»±c táº¿')
    plt.ylabel('Äiá»ƒm GPA dá»± Ä‘oÃ¡n')
else:
    plt.scatter(y_test, y_pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    plt.xlabel('Äiá»ƒm GPA thá»±c táº¿')
    plt.ylabel('Äiá»ƒm GPA dá»± Ä‘oÃ¡n')

plt.title('So sÃ¡nh Ä‘iá»ƒm GPA thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n')
st.pyplot(fig)
# PhÃ¢n tÃ­ch dÆ° thá»«a (residual analysis)
st.subheader("PhÃ¢n tÃ­ch dÆ° thá»«a (Residual Analysis)")

# Sá»­ dá»¥ng dá»¯ liá»‡u gá»‘c náº¿u Ä‘Ã£ Ã¡p dá»¥ng log transform
if use_log_transform:
    residuals = y_test_original - y_pred_original
else:
    residuals = y_test - y_pred

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Histogram cá»§a residuals
sns.histplot(residuals, kde=True, ax=axes[0])
axes[0].set_title("PhÃ¢n phá»‘i cá»§a Residuals")
axes[0].set_xlabel("Residuals")

# Scatter plot cá»§a residuals
if use_log_transform:
    sns.scatterplot(x=y_pred_original, y=residuals, ax=axes[1])
else:
    sns.scatterplot(x=y_pred, y=residuals, ax=axes[1])

axes[1].axhline(y=0, color='r', linestyle='-')
axes[1].set_title("Residuals vs Predicted Values")
axes[1].set_xlabel("Predicted Values")
axes[1].set_ylabel("Residuals")

st.pyplot(fig)

# Kiá»ƒm tra normalcy cá»§a residuals
_, p = stats.shapiro(residuals)
st.write(f"Kiá»ƒm tra tÃ­nh chuáº©n cá»§a residuals (Shapiro-Wilk test): p-value = {p:.4f}")
if p > 0.05:
    st.success("Residuals cÃ³ phÃ¢n phá»‘i chuáº©n (good)")
else:
    st.warning("Residuals khÃ´ng cÃ³ phÃ¢n phá»‘i chuáº©n (cÃ³ thá»ƒ cáº§n biáº¿n Ä‘á»•i dá»¯ liá»‡u)")
    # TÃ­nh toÃ¡n vÃ  hiá»ƒn thá»‹ há»‡ sá»‘
if model_type in ["Linear Regression", "Ridge Regression", "Lasso Regression", "ElasticNet"]:
    st.subheader("PhÃ¢n tÃ­ch chi tiáº¿t há»‡ sá»‘ há»“i quy")
    
    # Láº¥y feature names sau khi Ã¡p dá»¥ng cÃ¡c biáº¿n Ä‘á»•i
    feature_names_final = X.columns.tolist()
    
    # Náº¿u sá»­ dá»¥ng polynomial features, láº¥y tÃªn Ä‘áº·c trÆ°ng sau biáº¿n Ä‘á»•i
    if poly_degree > 1 and 'poly' in pipeline.named_steps:
        feature_names_final = pipeline.named_steps['poly'].get_feature_names_out(X.columns)
    
    # Náº¿u sá»­ dá»¥ng feature selection, chá»‰ láº¥y cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c chá»n
    if feature_selection and 'feature_selection' in pipeline.named_steps:
        selected_indices = pipeline.named_steps['feature_selection'].get_support()
        feature_names_final = np.array(feature_names_final)[selected_indices].tolist()
    
    # Láº¥y há»‡ sá»‘ tá»« mÃ´ hÃ¬nh
    try:
        coefficients = pipeline.named_steps['model'].coef_
        
        # Táº¡o DataFrame Ä‘á»ƒ hiá»ƒn thá»‹ há»‡ sá»‘
        coef_df = pd.DataFrame({
            'TÃ­nh nÄƒng': [feature_names.get(feat, feat) if feat in feature_names else feat 
                         for feat in feature_names_final],
            'Há»‡ sá»‘': coefficients
        })
        
        # Sáº¯p xáº¿p theo giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cá»§a há»‡ sá»‘
        coef_df['Há»‡ sá»‘ tuyá»‡t Ä‘á»‘i'] = np.abs(coef_df['Há»‡ sá»‘'])
        coef_df = coef_df.sort_values('Há»‡ sá»‘ tuyá»‡t Ä‘á»‘i', ascending=False)
        
        # Hiá»ƒn thá»‹ báº£ng há»‡ sá»‘
        st.write(coef_df)
        
        # Váº½ biá»ƒu Ä‘á»“ top 10 tÃ­nh nÄƒng quan trá»ng nháº¥t
        top_n = min(10, len(coef_df))
        plt.figure(figsize=(10, 6))
        colors = ['green' if x > 0 else 'red' for x in coef_df['Há»‡ sá»‘'][:top_n].values]
        plt.barh(coef_df['TÃ­nh nÄƒng'][:top_n], coef_df['Há»‡ sá»‘'][:top_n], color=colors)
        plt.xlabel('Há»‡ sá»‘')
        plt.title(f'Top {top_n} tÃ­nh nÄƒng quan trá»ng nháº¥t')
        plt.tight_layout()
        st.pyplot(plt)
        
        # Hiá»ƒn thá»‹ intercept
        if hasattr(pipeline.named_steps['model'], 'intercept_'):
            if isinstance(pipeline.named_steps['model'].intercept_, (list, np.ndarray)):
                st.write(f"Há»‡ sá»‘ cháº·n (Intercept): {pipeline.named_steps['model'].intercept_[0]:.4f}")
            else:
                st.write(f"Há»‡ sá»‘ cháº·n (Intercept): {pipeline.named_steps['model'].intercept_:.4f}")
            
    except (AttributeError, KeyError) as e:
        st.error(f"KhÃ´ng thá»ƒ hiá»ƒn thá»‹ há»‡ sá»‘ há»“i quy: {e}")
        # CÃ´ng cá»¥ dá»± Ä‘oÃ¡n
st.header("Dá»± Ä‘oÃ¡n káº¿t quáº£ há»c táº­p cho sinh viÃªn má»›i")
st.write("Nháº­p thÃ´ng tin cá»§a sinh viÃªn Ä‘á»ƒ dá»± Ä‘oÃ¡n Ä‘iá»ƒm GPA:")

# Táº¡o form nháº­p dá»¯ liá»‡u vá»›i tÃªn tiáº¿ng Viá»‡t
col1, col2 = st.columns(2)

with col1:
    gio_hoc = st.slider(feature_names['gio_hoc_moi_tuan'], 0, 60, 30)
    diem_dau_vao = st.slider(feature_names['diem_dau_vao'], 0.0, 10.0, 8.0)
    diem_tb_truoc = st.slider(feature_names['diem_trung_binh_truoc'], 0.0, 10.0, 7.5)
    tham_gia_nk = st.selectbox(feature_names['tham_gia_ngoai_khoa'], ["KhÃ´ng", "CÃ³"])

with col2:
    gio_giai_tri = st.slider(feature_names['gio_giai_tri'], 0, 60, 15)
    lam_them = st.selectbox(feature_names['lam_them'], ["KhÃ´ng", "CÃ³"])
    kc_truong = st.slider(feature_names['khoang_cach_den_truong'], 0, 50, 10)

# Chuyá»ƒn Ä‘á»•i giÃ¡ trá»‹
tham_gia_nk_value = 1 if tham_gia_nk == "CÃ³" else 0
lam_them_value = 1 if lam_them == "CÃ³" else 0

# Táº¡o DataFrame cho sinh viÃªn má»›i
new_student = pd.DataFrame({
    'gio_hoc_moi_tuan': [gio_hoc],
    'diem_dau_vao': [diem_dau_vao],
    'diem_trung_binh_truoc': [diem_tb_truoc],
    'tham_gia_ngoai_khoa': [tham_gia_nk_value],
    'gio_giai_tri': [gio_giai_tri],
    'lam_them': [lam_them_value],
    'khoang_cach_den_truong': [kc_truong]
})
# ThÃªm cÃ¡c Ä‘áº·c trÆ°ng tÆ°Æ¡ng tÃ¡c náº¿u Ä‘Ã£ sá»­ dá»¥ng
if use_interactions:
    new_student = add_interaction_features(new_student)

# Dá»± Ä‘oÃ¡n GPA cho sinh viÃªn má»›i
predicted_gpa = pipeline.predict(new_student)[0]

# Chuyá»ƒn Ä‘á»•i dá»± Ä‘oÃ¡n vá» giÃ¡ trá»‹ thá»±c náº¿u Ä‘Ã£ sá»­ dá»¥ng log transform
if use_log_transform:
    predicted_gpa = np.exp(predicted_gpa)

# Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
st.subheader("Káº¿t quáº£ dá»± Ä‘oÃ¡n")
st.markdown(f"### Äiá»ƒm GPA dá»± Ä‘oÃ¡n: {predicted_gpa:.2f}/10")

# ÄÃ¡nh giÃ¡ má»©c GPA báº±ng tiáº¿ng Viá»‡t
if predicted_gpa >= 8.5:
    st.success("ğŸŒŸ Xuáº¥t sáº¯c - Sinh viÃªn cÃ³ kháº£ nÄƒng Ä‘áº¡t thÃ nh tÃ­ch cao")
elif predicted_gpa >= 7.0:
    st.info("âœ… KhÃ¡ - Sinh viÃªn cÃ³ káº¿t quáº£ há»c táº­p tá»‘t")
elif predicted_gpa >= 5.0:
    st.warning("âš ï¸ Trung bÃ¬nh - Sinh viÃªn cáº§n cáº£i thiá»‡n phÆ°Æ¡ng phÃ¡p há»c táº­p")
else:
    st.error("âŒ Yáº¿u - Sinh viÃªn cáº§n ná»— lá»±c nhiá»u hÆ¡n vÃ  tÃ¬m kiáº¿m há»— trá»£")

# Gá»£i Ã½ cáº£i thiá»‡n
st.subheader("Gá»£i Ã½ cáº£i thiá»‡n")

suggestions = []

# PhÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng dá»±a trÃªn mÃ´ hÃ¬nh
if model_type in ["Linear Regression", "Ridge Regression", "Lasso Regression", "ElasticNet"]:
    # Láº¥y há»‡ sá»‘ tá»« mÃ´ hÃ¬nh
    try:
        coefficients = pipeline.named_steps['model'].coef_
        feature_names_final = X.columns.tolist()
        
        # Náº¿u sá»­ dá»¥ng polynomial features, láº¥y tÃªn Ä‘áº·c trÆ°ng sau biáº¿n Ä‘á»•i
        if poly_degree > 1 and 'poly' in pipeline.named_steps:
            feature_names_final = pipeline.named_steps['poly'].get_feature_names_out(X.columns)
        
        # Náº¿u sá»­ dá»¥ng feature selection, chá»‰ láº¥y cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c chá»n
        if feature_selection and 'feature_selection' in pipeline.named_steps:
            selected_indices = pipeline.named_steps['feature_selection'].get_support()
            feature_names_final = np.array(feature_names_final)[selected_indices].tolist()
        
        # Táº¡o tá»« Ä‘iá»ƒn Ã¡nh xáº¡ Ä‘áº·c trÆ°ng vÃ  há»‡ sá»‘
        feature_importances = dict(zip(feature_names_final, coefficients))
        
        # Chá»‰ xem xÃ©t cÃ¡c Ä‘áº·c trÆ°ng cÆ¡ báº£n cho gá»£i Ã½
        basic_features = ['gio_hoc_moi_tuan', 'diem_dau_vao', 'diem_trung_binh_truoc', 
                         'tham_gia_ngoai_khoa', 'gio_giai_tri', 'lam_them', 'khoang_cach_den_truong']
        
        # Lá»c há»‡ sá»‘ cho cÃ¡c Ä‘áº·c trÆ°ng cÆ¡ báº£n
        basic_importances = {}
        for feature in basic_features:
            for key, value in feature_importances.items():
                if feature in key:  # Xá»­ lÃ½ cáº£ trÆ°á»ng há»£p Ä‘a thá»©c
                    if feature not in basic_importances:
                        basic_importances[feature] = value
                    else:
                        basic_importances[feature] += value  # Cá»™ng dá»“n há»‡ sá»‘ náº¿u Ä‘Ã£ cÃ³
        
        # Sáº¯p xáº¿p theo má»©c Ä‘á»™ quan trá»ng
        sorted_features = sorted(basic_importances.items(), key=lambda x: abs(x[1]), reverse=True)
        
        # ÄÆ°a ra gá»£i Ã½ dá»±a trÃªn há»‡ sá»‘
        for feature, coef in sorted_features[:3]:
            if coef > 0:  # Yáº¿u tá»‘ tÃ­ch cá»±c
                if feature == 'gio_hoc_moi_tuan' and gio_hoc < 30:
                    suggestions.append(f"TÄƒng {feature_names[feature].lower()} tá»« {gio_hoc} lÃªn khoáº£ng 30-35 giá»/tuáº§n cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘iá»ƒm GPA.")
                elif feature == 'tham_gia_ngoai_khoa' and tham_gia_nk_value == 0:
                    suggestions.append(f"NÃªn {feature_names[feature].lower()} Ä‘á»ƒ giÃºp cáº£i thiá»‡n ká»¹ nÄƒng vÃ  Ä‘iá»ƒm GPA.")
                elif feature == 'diem_dau_vao' or feature == 'diem_trung_binh_truoc':
                    suggestions.append(f"{feature_names[feature]} tá»‘t lÃ  yáº¿u tá»‘ quan trá»ng áº£nh hÆ°á»Ÿng tÃ­ch cá»±c Ä‘áº¿n Ä‘iá»ƒm GPA.")
            else:  # Yáº¿u tá»‘ tiÃªu cá»±c
                if feature == 'gio_giai_tri' and gio_giai_tri > 20:
                    suggestions.append(f"Giáº£m {feature_names[feature].lower()} tá»« {gio_giai_tri} xuá»‘ng dÆ°á»›i 20 giá»/tuáº§n cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘iá»ƒm GPA.")
                elif feature == 'lam_them' and lam_them_value == 1:
                    suggestions.append(f"{feature_names[feature]} cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng tiÃªu cá»±c Ä‘áº¿n Ä‘iá»ƒm GPA. CÃ¢n nháº¯c giáº£m thá»i gian lÃ m thÃªm náº¿u cÃ³ thá»ƒ.")
                elif feature == 'khoang_cach_den_truong' and kc_truong > 20:
                    suggestions.append(f"{feature_names[feature]} dÃ i ({kc_truong} km) cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng tiÃªu cá»±c Ä‘áº¿n thá»i gian há»c táº­p. Náº¿u cÃ³ thá»ƒ, hÃ£y cÃ¢n nháº¯c tÃ¬m chá»— á»Ÿ gáº§n trÆ°á»ng hÆ¡n.")
    except (AttributeError, KeyError) as e:
        st.error(f"KhÃ´ng thá»ƒ phÃ¢n tÃ­ch há»‡ sá»‘ cho gá»£i Ã½: {e}")
        # Sá»­ dá»¥ng gá»£i Ã½ chung náº¿u khÃ´ng thá»ƒ phÃ¢n tÃ­ch cá»¥ thá»ƒ
        suggestions = [
            "CÃ¢n báº±ng giá»¯a thá»i gian há»c táº­p vÃ  giáº£i trÃ­",
            "Tham gia cÃ¡c hoáº¡t Ä‘á»™ng ngoáº¡i khÃ³a phÃ¹ há»£p Ä‘á»ƒ phÃ¡t triá»ƒn ká»¹ nÄƒng má»m",
            "TÃ¬m mÃ´i trÆ°á»ng há»c táº­p phÃ¹ há»£p Ä‘á»ƒ tÄƒng hiá»‡u quáº£"
        ]
else:
    # Gá»£i Ã½ chung cho cÃ¡c mÃ´ hÃ¬nh ensemble
    suggestions = [
        "TÄƒng thá»i gian há»c táº­p hiá»‡u quáº£, táº­p trung vÃ o cháº¥t lÆ°á»£ng hÆ¡n sá»‘ lÆ°á»£ng",
        "CÃ¢n báº±ng giá»¯a há»c táº­p vÃ  cÃ¡c hoáº¡t Ä‘á»™ng khÃ¡c",
        "TÃ¬m kiáº¿m sá»± há»— trá»£ tá»« giáº£ng viÃªn vÃ  báº¡n há»c khi gáº·p khÃ³ khÄƒn"
    ]

# Hiá»ƒn thá»‹ cÃ¡c gá»£i Ã½
if suggestions:
    for suggestion in suggestions:
        st.write(f"- {suggestion}")
else:
    st.write("- Duy trÃ¬ thÃ³i quen há»c táº­p hiá»‡n táº¡i Ä‘á»ƒ Ä‘áº¡t káº¿t quáº£ tá»‘t.")
    st.write("- CÃ¢n báº±ng giá»¯a há»c táº­p vÃ  hoáº¡t Ä‘á»™ng khÃ¡c Ä‘á»ƒ trÃ¡nh kiá»‡t sá»©c.")
    # ThÃªm pháº§n so sÃ¡nh vá»›i dá»± Ä‘oÃ¡n mÃ´ hÃ¬nh cÆ¡ báº£n
st.subheader("So sÃ¡nh vá»›i mÃ´ hÃ¬nh cÆ¡ báº£n")

# Táº¡o má»™t mÃ´ hÃ¬nh cÆ¡ báº£n Ä‘á»ƒ so sÃ¡nh
basic_model = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LinearRegression())
])

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh cÆ¡ báº£n trÃªn dá»¯ liá»‡u gá»‘c
X_basic = df.drop('gpa', axis=1)
y_basic = df['gpa']
basic_model.fit(X_basic, y_basic)

# Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh cÆ¡ báº£n
basic_prediction = basic_model.predict(new_student[X_basic.columns])[0]

# Hiá»ƒn thá»‹ so sÃ¡nh
col1, col2 = st.columns(2)
with col1:
    st.metric("Dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh cáº£i tiáº¿n", f"{predicted_gpa:.2f}")
with col2:
    st.metric("Dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh cÆ¡ báº£n", f"{basic_prediction:.2f}", 
              delta=f"{predicted_gpa - basic_prediction:.2f}")

# ThÃªm thÃ´ng tin giáº£i thÃ­ch vá» sá»± khÃ¡c biá»‡t
if abs(predicted_gpa - basic_prediction) > 0.5:
    st.info("""
    **Giáº£i thÃ­ch sá»± khÃ¡c biá»‡t:** MÃ´ hÃ¬nh cáº£i tiáº¿n xem xÃ©t cÃ¡c tÆ°Æ¡ng tÃ¡c phá»©c táº¡p giá»¯a cÃ¡c yáº¿u tá»‘ 
    vÃ  Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ¢ng cao nÃªn cÃ³ thá»ƒ cho káº¿t quáº£ dá»± Ä‘oÃ¡n khÃ¡c biá»‡t so vá»›i mÃ´ hÃ¬nh cÆ¡ báº£n.
    """)

# ThÃªm pháº§n giá»›i thiá»‡u vá» mÃ´ hÃ¬nh
st.header("ThÃ´ng tin vá» mÃ´ hÃ¬nh")
st.write("""
á»¨ng dá»¥ng nÃ y sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t há»c mÃ¡y Ä‘á»ƒ dá»± Ä‘oÃ¡n káº¿t quáº£ há»c táº­p (GPA) cá»§a sinh viÃªn 
dá»±a trÃªn cÃ¡c yáº¿u tá»‘ Ä‘áº§u vÃ o. MÃ´ hÃ¬nh Ä‘Æ°á»£c cáº£i tiáº¿n vá»›i:

1. **Feature Engineering nÃ¢ng cao**: Táº¡o Ä‘áº·c trÆ°ng tÆ°Æ¡ng tÃ¡c, biáº¿n Ä‘á»•i Ä‘a thá»©c, lá»±a chá»n Ä‘áº·c trÆ°ng
2. **Xá»­ lÃ½ dá»¯ liá»‡u tá»‘t hÆ¡n**: Loáº¡i bá» outliers, biáº¿n Ä‘á»•i logarithm cho biáº¿n má»¥c tiÃªu náº¿u cáº§n
3. **Tá»‘i Æ°u hÃ³a siÃªu tham sá»‘**: TÃ¬m giÃ¡ trá»‹ tá»‘t nháº¥t cho cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh
4. **ÄÃ¡nh giÃ¡ toÃ n diá»‡n**: Cross-validation, phÃ¢n tÃ­ch residual, so sÃ¡nh mÃ´ hÃ¬nh

CÃ¡c cáº£i tiáº¿n nÃ y giÃºp tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh, Ä‘áº·c biá»‡t khi lÃ m viá»‡c vá»›i dá»¯ liá»‡u phá»©c táº¡p.
""")

# ThÃªm pháº§n giá»›i thiá»‡u vá» dá»± Ã¡n
st.sidebar.markdown("---")
st.sidebar.subheader("ThÃ´ng tin dá»± Ã¡n")
st.sidebar.info("""
**Dá»± Ã¡n Dá»± Ä‘oÃ¡n káº¿t quáº£ há»c táº­p cá»§a sinh viÃªn**

PhiÃªn báº£n: 2.0 (Cáº£i tiáº¿n)
""")
